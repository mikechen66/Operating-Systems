# GPU-Parallel-Program-Development
Tolga Soyata

CUDA (Compute Unified Device Architecture) is a parallel computing platform and application programming interface (API) model created by Nvidia. It allows software developers and software engineers to use a CUDA-enabled graphics processing unit (GPU) for general purpose processing â€“ an approach termed GPGPU (general-purpose computing on graphics processing units). The CUDA platform is a software layer that gives direct access to the GPU's virtual instruction set and parallel computational elements, for the execution of compute kernels.

The CUDA platform is designed to work with programming languages such as C, C++, and Fortran. This accessibility makes it easier for specialists in parallel programming to use GPU resources. CUDA-powered GPUs also support programming frameworks such as OpenMP, OpenACC and OpenCL;and HIP by compiling such code to CUDA. 

Resources: 

Book Excerpt: 

https://andrewboggio.com/pdf/soyata.crc18.pdf


Nvidia CUDA C Programming: 

https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html


Stanford CUDA Parallel Programming: 

https://mc.stanford.edu/cgi-bin/images/b/ba/M02_2.pdf

Parallel Programming for GPUs - Utah CS6963 

http://www.cs.utah.edu/~mhall/cs6963s09/


CUDA By Example(2011): 

http://www.mat.unimi.it/users/sansotte/cuda/CUDA_by_Example.pdf


Programming for GPUs using CUDA in C/C++

https://www.bu.edu/tech/support/research/software-and-programming/programming/multiprocessor/gpu-computing/cuda-c/
